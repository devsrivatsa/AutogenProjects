{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autogen\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4-1106-preview\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "    },\n",
    "]\n",
    "\n",
    "llm_config={\n",
    "    # \"cache_seed\":42,\n",
    "    \"temperature\":0,\n",
    "    \"config_list\":config_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful AI assistant. You suggest coding and reasoning steps for another AI assistant. Do not suggest concrete code. For any action beyond writing code or reasoning, convert it to a step that can be implemented by writing code. For example, browsing the web can be implemented by writing code that reads and prints the content of a web page. Finally, inspect the execution result. If the plan is not good, suggest a better plan. If the execution is wrong, analyze the error and suggest a fix.\"\n",
    ")\n",
    "\n",
    "planner_user = autogen.UserProxyAgent(\n",
    "    name=\"planner_user\",\n",
    "    max_consecutive_auto_reply=0,\n",
    "    human_input_mode=\"NEVER\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_planner(message):\n",
    "    planner_user.initiate_chat(planner, message=message)\n",
    "    return planner_user.last_message()[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = autogen.AssistantAgent(\n",
    "    name = \"assistant\",\n",
    "    llm_config = {\n",
    "        \"temperature\": 0,\n",
    "        \"timeout\": 600,\n",
    "        \"config_list\": config_list,\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"ask_planner\",\n",
    "                \"description\": \"ask planner to 1. get a plan for finishing a task, 2. verify the execution result of the plan and potentially suggest new plan.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"message\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"question to ask_planner. Make sure the question includes enough context, such as the code and the execution result.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"message\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    # is_termination_msg=lambda x: \"content\" in x and x[\"content\"] is not None and x[\"content\"].rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\"work_dir\": \"planning\"},\n",
    "    function_map={\"ask_planner\": ask_planner},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_proxy.initiate_chat(\n",
    "#     assistant,\n",
    "#     message = \"Suggest a fix to an open good first issue of flaml\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyautogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
